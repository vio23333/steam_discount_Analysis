from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager
import time
import pandas as pd
import random

def crawl_page(driver, page_num):
    url = f"https://store.steampowered.com/search/?specials=1&page={page_num}"
    driver.get(url)
    time.sleep(2 + random.random())

    rows = driver.find_elements(By.CLASS_NAME, "search_result_row")
    result = []

    # å¦‚æœé€™ä¸€é æ²’æœ‰ä»»ä½•éŠæˆ² â†’ å›å‚³ç©ºé™£åˆ—ï¼Œä¸»ç¨‹å¼æœƒè‡ªå‹• break
    if len(rows) == 0:
        return result

    for row in rows:
        try:
            name = row.find_element(By.CLASS_NAME, "title").text.strip()
        except:
            name = None

        try:
            release = row.find_element(By.CLASS_NAME, "search_released").text.strip()
        except:
            release = None

        try:
            review = row.find_element(By.CLASS_NAME, "search_review_summary")
            review_level = review.get_attribute("data-tooltip-html")
            if review_level:
                review_level = review_level.split("<br>")[0].strip()
        except:
            review_level = None

        try:
            original_price = row.find_element(By.CLASS_NAME, "discount_original_price").text.strip()
            final_price = row.find_element(By.CLASS_NAME, "discount_final_price").text.strip()
        except:
            original_price = None
            final_price = None

        try:
            discount = row.find_element(By.CLASS_NAME, "discount_pct").text.strip()
        except:
            discount = None

        result.append({
            "Name": name,
            "Original_Price": original_price,
            "Final_Price": final_price,
            "Discount": discount,
            "Release_Date": release,
            "Review_Level": review_level
        })

    return result


if __name__ == "__main__":
    print("ğŸš€ é–‹å§‹çˆ¬å– Steam ç‰¹åƒ¹è³‡æ–™ï¼ˆSelenium åˆ†é ç‰ˆï¼Œè‡ªå‹•åœæ­¢ï¼‰\n")

    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))

    all_data = []
    page = 1

    while True:
        print(f"ğŸ“„ æ­£åœ¨æŠ“ç¬¬ {page} é ...")

        page_data = crawl_page(driver, page)

        #è‡ªå‹•åµæ¸¬æœ€å¾Œä¸€é ï¼šæ²’è³‡æ–™å°±åœæ­¢
        if len(page_data) == 0:
            print("âœ… å·²ç„¡æ›´å¤šé é¢ï¼Œè³‡æ–™çˆ¬å–å®Œæˆï¼")
            break

        all_data.extend(page_data)

        page += 1
        time.sleep(1 + random.random())

    driver.quit()

    df = pd.DataFrame(all_data)
    df.to_excel("steam_specials_selenium_pages.xlsx", index=False)

    print("\nâœ… å®Œæˆï¼å·²è¼¸å‡º steam_specials_selenium_pages.xlsx")
    print(f"âœ… å…±æŠ“å– {len(df)} ç­†è³‡æ–™ã€‚")
